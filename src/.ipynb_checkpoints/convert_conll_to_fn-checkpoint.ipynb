{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fndir = './bakup/180909/resource/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with open(fndir+'KFN_lus.json','r') as f:\n",
    "        kfn = json.load(f)\n",
    "    return kfn\n",
    "kfn = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv():\n",
    "    with open('./koreanframenet/data/training.tsv','r') as f:\n",
    "        trn = f.readlines()\n",
    "    with open('./koreanframenet/data/test.tsv','r') as f:\n",
    "        tst = f.readlines()\n",
    "    with open('./koreanframenet/data/dev.tsv','r') as f:\n",
    "        dev = f.readlines()\n",
    "    trn.append('\\n')\n",
    "    tst.append('\\n')\n",
    "    tst.append('\\n')\n",
    "    cdata = trn+tst+dev\n",
    "    sent = []\n",
    "    d = {}\n",
    "    result = []\n",
    "    n_of_sents = 0\n",
    "    sent_idx = {}\n",
    "    # 1) gen sent_id and its text:\n",
    "    for line in cdata:\n",
    "        line = line.rstrip('\\n')\n",
    "        if line.startswith('#'):\n",
    "            if line[1] == 's':\n",
    "                sent_id = int(line.split(':')[1])\n",
    "            if line[1] == 't':\n",
    "                text = line.split('text:')[1]\n",
    "                text_list = text.split(' ')\n",
    "                text = ' '.join(text_list)\n",
    "        else:\n",
    "            if sent_id and text:\n",
    "                sent_idx[sent_id] = text\n",
    "            sent_id = False\n",
    "            text = False\n",
    "    anno_idx = {}\n",
    "    for line in cdata:\n",
    "        line = line.rstrip('\\n')\n",
    "        if line.startswith('#'):\n",
    "            if line[1] == 's':\n",
    "                sent_id = int(line.split(':')[1])\n",
    "        else:\n",
    "            if line != '':\n",
    "                token = line.split('\\t')\n",
    "                sent.append(token)\n",
    "            else:\n",
    "                exist = False\n",
    "                for a in anno_idx:\n",
    "                    if sent_id == a:\n",
    "                        exist = True\n",
    "                if exist:\n",
    "                    annotations = anno_idx[sent_id]\n",
    "                    annotations.append(sent)\n",
    "                    anno_idx[sent_id] = annotations\n",
    "#                     break\n",
    "                else:\n",
    "                    annotations = []\n",
    "                    annotations.append(sent)\n",
    "                    anno_idx[sent_id] = annotations\n",
    "                sent = []\n",
    "    return sent_idx, anno_idx                   \n",
    "\n",
    "sent_idx, anno_idx = load_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "태풍 Hugo가 남긴 피해들과 회사 내 몇몇 주요 부서들의 저조한 실적들을 반영하여, Aetna Life and Casualty Co.의 3분기 순이익이 182.6 백만 달러 또는 주당 1.63 달러로 22 % 하락하였다.\n"
     ]
    }
   ],
   "source": [
    "print(sent_idx[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anno(sent_id):\n",
    "#     print('input:',sent_id)\n",
    "    result = False\n",
    "    with open(fndir+'KFN_annotations.json','r') as f:\n",
    "        annos = json.load(f)\n",
    "    for i in annos:\n",
    "        origin_id = i['text']['sent_id']\n",
    "        if sent_id == origin_id:\n",
    "            result = i\n",
    "    if result:\n",
    "        return result\n",
    "    else:\n",
    "        print('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(tokens):\n",
    "    frame = False\n",
    "    for token in tokens:\n",
    "        if token[13] != '_':\n",
    "            frame = token[13]\n",
    "    if frame:\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lu(tokens):\n",
    "    lu = False\n",
    "    for token in tokens:\n",
    "        if token[12] != '_':\n",
    "            lu = token[12]\n",
    "    if lu:\n",
    "        return lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(tokens):\n",
    "    target = False\n",
    "    for token in tokens:\n",
    "        if token[12] != '_':\n",
    "            target = token[12]\n",
    "            target_id = int(token[0])\n",
    "    if target:\n",
    "        return target, target_id\n",
    "    else:\n",
    "        print('ERROR_get_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_annoframe(ko_annotation_id):\n",
    "    frame = False\n",
    "    for i in kfn:\n",
    "        if ko_annotation_id in i['ko_annotation_id']:\n",
    "            frame = i['frameName']\n",
    "            break\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anno_item(anno, target_span, frame):\n",
    "    b = target_span['begin']\n",
    "    e = target_span['end']\n",
    "    result = False\n",
    "    for i in anno['frameAnnotation']['ko_annotations']:\n",
    "        ko_annotation_id = i['ko_annotation_id']\n",
    "        ori_frame = i['frameName']\n",
    "        rev_frame = rev_annoframe(ko_annotation_id)\n",
    "        if rev_frame:\n",
    "            pass\n",
    "        else:\n",
    "            rev_frame = ori_frame\n",
    "        if frame == rev_frame:\n",
    "            ori_b = -1\n",
    "            ori_e = -1\n",
    "            for d in i['denotations']:\n",
    "                if d['obj'] == 'target':\n",
    "                    ori_b = int(d['span']['begin'])\n",
    "                    ori_e = int(d['span']['end'])\n",
    "            if ori_b >= 0:\n",
    "                if b <= ori_b and ori_e <= e:\n",
    "                    result = i\n",
    "                    break\n",
    "                \n",
    "    if result == False:\n",
    "        for i in anno['frameAnnotation']['ko_annotations']:\n",
    "            ko_annotation_id = i['ko_annotation_id']\n",
    "            rev_frame = rev_annoframe(ko_annotation_id)\n",
    "            if frame == rev_frame:\n",
    "                result = i\n",
    "                break\n",
    "                \n",
    "    if result:\n",
    "        return result\n",
    "    else:\n",
    "        print('ERROR_get_anno_item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_origin_item(sent_id):\n",
    "    text_item = False\n",
    "    frame_item = False\n",
    "    with open(fndir+'KFN_annotations.json','r') as f:\n",
    "        annos = json.load(f)\n",
    "    for i in annos:\n",
    "        text_i = i['text']\n",
    "        frame_i = i['frameAnnotation']\n",
    "        if sent_id == text_i['sent_id']:\n",
    "            text_item = text_i\n",
    "            frame_item = frame_i\n",
    "            break\n",
    "    if text_item and frame_item:\n",
    "        return text_item, frame_item\n",
    "    else:\n",
    "        print('ERROR_get_origin_item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relations(denos):\n",
    "    relations = []\n",
    "    for i in denos:\n",
    "        if i['role'] == 'ARGUMENT':\n",
    "            did = i['id']\n",
    "            relation = {}\n",
    "            relation['subj'] = 1\n",
    "            relation['obj'] = did\n",
    "            relation['pred'] = 'arg'\n",
    "            relations.append(relation)\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'begin': 3, 'end': 9}\n"
     ]
    }
   ],
   "source": [
    "def get_token_span(token_ids, text):\n",
    "    text = text.split(' ')\n",
    "    d = {}\n",
    "    cid = -1\n",
    "    for i in range(len(text)):\n",
    "        if i == 0:\n",
    "            d[i] = (0, len(text[i]))\n",
    "            cid = len(text[i]) +1\n",
    "        else:\n",
    "            d[i] = (cid, cid+len(text[i]))\n",
    "            cid =  cid+len(text[i]) +1\n",
    "    start = True\n",
    "    for i in token_ids:\n",
    "        if start == True:\n",
    "            begin = d[i][0]\n",
    "            start = False\n",
    "        end = d[i][1]\n",
    "    span = {}\n",
    "    span['begin'] = begin\n",
    "    span['end'] = end\n",
    "    return span\n",
    "        \n",
    "        \n",
    "text = '나는 밥을 먹었다'\n",
    "span = get_token_span([1,2], text)\n",
    "print(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_denotations(tokens, text, frame_index):\n",
    "    # 1) find target\n",
    "    target_ids = []\n",
    "    for token in tokens:\n",
    "        if token[12] != '_':\n",
    "            target_ids.append(int(token[0]))\n",
    "            target = token[12]\n",
    "    span = get_token_span(target_ids, text)\n",
    "    deno = {}\n",
    "    deno['id'] = 1\n",
    "    deno['obj'] = frame_index\n",
    "    deno['span'] = span\n",
    "    deno['token_span'] = target_ids\n",
    "    deno['role'] = 'TARGET'\n",
    "    b = span['begin']\n",
    "    e = span['end']\n",
    "    deno['text'] = text[b:e]\n",
    "    denos = []\n",
    "    denos.append(deno)\n",
    "    # 2) find arguments\n",
    "    fe_id = 2\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i][14] != 'O':\n",
    "            fe_bio = tokens[i][14]\n",
    "#             print(i, fe_bio)\n",
    "            fe_list = fe_bio.split('_')[1:]\n",
    "            fe = '_'.join(fe_list)\n",
    "            if fe_bio.startswith('B'):\n",
    "                d = {}\n",
    "                d['id'] = fe_id\n",
    "                d['obj'] = fe.title()                \n",
    "                n = 1\n",
    "                arg_span = []\n",
    "                arg_span.append(int(tokens[i][0]))\n",
    "                nextfe = False\n",
    "                while i+n < len(tokens):\n",
    "                    nextfe = tokens[i+n][14]\n",
    "                    if nextfe == 'I_'+fe:\n",
    "                        arg_span.append(int(tokens[i+n][0]))\n",
    "                        n += 1\n",
    "                    else:\n",
    "                        break                    \n",
    "                fe_id += 1\n",
    "                d['token_span'] = arg_span\n",
    "                span = get_token_span(arg_span, text)\n",
    "                d['span'] = span\n",
    "                b = span['begin']\n",
    "                e = span['end']\n",
    "                d['text'] = text[b:e]\n",
    "                d['role'] = 'ARGUMENT'\n",
    "                denos.append(d)\n",
    "            elif fe_bio.startswith('S'):\n",
    "                fe_bio = tokens[i][14]\n",
    "                fe_list = fe_bio.split('_')[1:]\n",
    "                fe = '_'.join(fe_list)\n",
    "                d = {}\n",
    "                d['id'] = fe_id\n",
    "                d['obj'] = fe.title()\n",
    "                token_span = [ int(tokens[i][0]) ]\n",
    "                d['token_span'] = token_span\n",
    "                span = get_token_span(token_span, text)\n",
    "                d['span'] = span\n",
    "                b = span['begin']\n",
    "                e = span['end']\n",
    "                d['text'] = text[b:e]\n",
    "                d['role'] = 'ARGUMENT'\n",
    "                fe_id += 1\n",
    "                denos.append(d)\n",
    "            else:\n",
    "                pass\n",
    "    if denos:\n",
    "        return denos\n",
    "    else:\n",
    "        print('ERROR_gen_denotations')\n",
    "            \n",
    "            \n",
    "#     for i in tokens:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sid: 5025\n",
      "text: 이 시스템으로는, 동영상과 음성을 포함한 각종 판매촉진자료를 데이터베이스화해 사내에서 일원 관리할 수 있고, 컴퓨터로 모든 정보를 검색할 수 있다.\n",
      "[[['0', '이', '이/MM', '이', 'MM', 'MM', '_', '_', '1', '1', 'DP', 'DP', '_', '_', 'B_entity'], ['1', '시스템으로는,', '시스템/NNG+으로/JKB+는/JX+,/SP', '시스템으로는,', 'NNG+JKB+JX+SP', 'NNG+JKB+JX+SP', '_', '_', '7', '7', 'NP_SBJ', 'NP_SBJ', '_', '_', 'I_entity'], ['2', '동영상과', '동영상/NNG+과/JC', '동영상과', 'NNG+JC', 'NNG+JC', '_', '_', '3', '3', 'NP_CNJ', 'NP_CNJ', '_', '_', 'O'], ['3', '음성을', '음성/NNG+을/JKO', '음성을', 'NNG+JKO', 'NNG+JKO', '_', '_', '4', '4', 'NP_OBJ', 'NP_OBJ', '_', '_', 'O'], ['4', '포함한', '포함하/VV+ㄴ/ETM', '포함한', 'VV+ETM', 'VV+ETM', '_', '_', '6', '6', 'VP_MOD', 'VP_MOD', '_', '_', 'O'], ['5', '각종', '각종/NNG', '각종', 'NNG', 'NNG', '_', '_', '6', '6', 'NP', 'NP', '_', '_', 'O'], ['6', '판매촉진자료를', '판매촉진자료/NNG+를/JKO', '판매촉진자료를', 'NNG+JKO', 'NNG+JKO', '_', '_', '7', '7', 'NP_OBJ', 'NP_OBJ', '_', '_', 'O'], ['7', '데이터베이스화해', '데이터베이스화/NNG+하/VV+어/EC', '데이터베이스화해', 'NNG+VV+EC', 'NNG+VV+EC', '_', '_', '10', '10', 'VP', 'VP', '_', '_', 'O'], ['8', '사내에서', '사내/NNG+에서/JKB', '사내에서', 'NNG+JKB', 'NNG+JKB', '_', '_', '10', '10', 'NP_AJT', 'NP_AJT', '_', '_', 'O'], ['9', '일원', '일원/NNG', '일원', 'NNG', 'NNG', '_', '_', '10', '10', 'NP', 'NP', '_', '_', 'O'], ['10', '관리할', '관리하/VV+ㄹ/ETM', '관리할', 'VV+ETM', 'VV+ETM', '_', '_', '11', '11', 'VP_MOD', 'VP_MOD', '_', '_', 'O'], ['11', '수', '수/NNB', '수', 'NNB', 'NNB', '_', '_', '12', '12', 'NP_SBJ', 'NP_SBJ', '_', '_', 'O'], ['12', '있고,', '있/VA+고/EC+,/SP', '있고,', 'VA+EC+SP', 'VA+EC+SP', '_', '_', '16', '16', 'VP', 'VP', '_', '_', 'O'], ['13', '컴퓨터로', '컴퓨터/NNG+로/JKB', '컴퓨터로', 'NNG+JKB', 'NNG+JKB', '_', '_', '16', '16', 'NP_AJT', 'NP_AJT', '_', '_', 'B_event'], ['14', '모든', '모든/MM', '모든', 'MM', 'MM', '_', '_', '15', '15', 'DP', 'DP', '_', '_', 'I_event'], ['15', '정보를', '정보/NNG+를/JKO', '정보를', 'NNG+JKO', 'NNG+JKO', '_', '_', '16', '16', 'NP_OBJ', 'NP_OBJ', '_', '_', 'I_event'], ['16', '검색할', '검색하/VV+ㄹ/ETM', '검색할', 'VV+ETM', 'VV+ETM', '_', '_', '17', '17', 'VP_MOD', 'VP_MOD', '_', '_', 'I_event'], ['17', '수', '수/NNB', '수', 'NNB', 'NNB', '_', '_', '18', '18', 'NP_SBJ', 'NP_SBJ', '_', '_', 'I_event'], ['18', '있다.', '있/VA+다/EF+./SF', '있다.', 'VA+EF+SF', 'VA+EF+SF', '_', '_', '-1', '-1', 'VP', 'VP', '있다.a', 'Capability', 'O']], []]\n",
      "0 _\n",
      "1 _\n",
      "2 _\n",
      "3 _\n",
      "4 _\n",
      "5 _\n",
      "6 _\n",
      "7 _\n",
      "8 _\n",
      "9 _\n",
      "10 _\n",
      "11 _\n",
      "12 _\n",
      "13 _\n",
      "14 _\n",
      "15 _\n",
      "16 _\n",
      "17 _\n",
      "18 있다.a\n",
      "1 annotations are saved.\n",
      "\n",
      "1 sentences\n",
      "1 annotations\n"
     ]
    }
   ],
   "source": [
    "def gen_annotation():\n",
    "    sentlist = []\n",
    "    for i in sent_idx:\n",
    "        sentlist.append(i)\n",
    "    \n",
    "    ko_annotation_id = 0\n",
    "    annotation_file = []\n",
    "    for sent_id in sentlist:\n",
    "#         sent_id = 5025\n",
    "        annotation_file_item = {}\n",
    "        \n",
    "        text = sent_idx[sent_id]\n",
    "        text_item, frame_item = get_origin_item(sent_id)\n",
    "        text_item['ko_text'] = text\n",
    "        annotation_file_item['text'] = text_item\n",
    "\n",
    "        annotations = anno_idx[sent_id]\n",
    "        anno = get_anno(sent_id)\n",
    "        print('sid:', sent_id)\n",
    "        print('text:',text)   \n",
    "        anno_items = []\n",
    "        for a in annotations:\n",
    "#             print(a)\n",
    "            if a:\n",
    "                frame = get_frame(a)\n",
    "                target, target_id = get_target(a)\n",
    "                lu = get_lu(a)\n",
    "                lu = lu+'.'+frame\n",
    "    #             print('frame', frame)\n",
    "                denos = gen_denotations(a, text, frame)\n",
    "                for i in denos:\n",
    "                    if i['role'] == 'TARGET':\n",
    "                        target_span = i['span']\n",
    "                anno_item = get_anno_item(anno, target_span, frame)\n",
    "                try:\n",
    "                    origin_lus = anno_item['origin_lus']\n",
    "                except KeyboardInterrupt:\n",
    "                    raise\n",
    "                except:\n",
    "                    origin_lus = []\n",
    "                for i in origin_lus:\n",
    "                    i = i.lower()\n",
    "                origin_lus = list(set(origin_lus))\n",
    "                anno_item['origin_lus'] = origin_lus\n",
    "                anno_item['denotations'] = denos\n",
    "                anno_item['frameName'] = frame\n",
    "                relations = get_relations(denos)\n",
    "                anno_item['relations'] = relations\n",
    "                anno_item['ko_annotation_id'] = ko_annotation_id\n",
    "                anno_item['lu'] = lu\n",
    "    #             anno_item['target'] = target\n",
    "                anno_items.append(anno_item)\n",
    "                ko_annotation_id += 1\n",
    "    \n",
    "        frame_item['ko_annotations'] = anno_items\n",
    "        annotation_file_item['frameAnnotation'] = frame_item\n",
    "        print(len(anno_items),'annotations are saved.\\n')\n",
    "        annotation_file.append(annotation_file_item)\n",
    "        \n",
    "        \n",
    "#         break  \n",
    "    with open('./KFN_annotations.json','w') as f:\n",
    "        json.dump(annotation_file, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    print(len(annotation_file), 'sentences')\n",
    "    print(ko_annotation_id, 'annotations')\n",
    "        \n",
    "# gen_annotation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(fndir+'KFN_annotations.json','r') as f:\n",
    "#     annos = json.load(f)\n",
    "# for i in annos:\n",
    "#     k = i['frameAnnotation']['ko_annotations']\n",
    "#     frames = []\n",
    "#     for j in k:\n",
    "#         f = j['frameName']\n",
    "#         if f in frames:\n",
    "#             print(i['text']['sent_id'])\n",
    "#         frames.append(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
